{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HyMZ3KHuKAE"
      },
      "source": [
        "# **YOLOv9 with BYTEtrack implementation (Ultralytics)**\n",
        "First of all, you need to Add folders by Adding shortcut to MyDrive\n",
        "\n",
        "*   Code & dataset\n",
        "  *   Asoke_north_video (For who want to use Asoke videos)\n",
        "  *   Makkasan (For who want to use Makkasan videos)\n",
        "*   poom (There is optimized .yaml for Asoke_north and Makkasan)\n",
        "*   etc.\n",
        "\n",
        "This code is made by Poom Ratsamewesarat ME105 #ME2 (2024-2025) (Any questions, contact me!)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GH96ZoJdm-F"
      },
      "source": [
        "# Set up\n",
        "Can click run all when this tap is collapsed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "GintQ_v6A2dA",
        "outputId": "492cadbf-8e66-4a95-dc99-7665415dc011"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ultralytics in ./.venv/lib/python3.12/site-packages (8.3.203)\n",
            "Requirement already satisfied: numpy>=1.23.0 in ./.venv/lib/python3.12/site-packages (from ultralytics) (2.2.6)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in ./.venv/lib/python3.12/site-packages (from ultralytics) (3.10.6)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in ./.venv/lib/python3.12/site-packages (from ultralytics) (4.12.0.88)\n",
            "Requirement already satisfied: pillow>=7.1.2 in ./.venv/lib/python3.12/site-packages (from ultralytics) (11.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in ./.venv/lib/python3.12/site-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in ./.venv/lib/python3.12/site-packages (from ultralytics) (2.32.5)\n",
            "Requirement already satisfied: scipy>=1.4.1 in ./.venv/lib/python3.12/site-packages (from ultralytics) (1.16.2)\n",
            "Requirement already satisfied: torch>=1.8.0 in ./.venv/lib/python3.12/site-packages (from ultralytics) (2.8.0)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in ./.venv/lib/python3.12/site-packages (from ultralytics) (0.23.0)\n",
            "Requirement already satisfied: psutil in ./.venv/lib/python3.12/site-packages (from ultralytics) (7.1.0)\n",
            "Requirement already satisfied: polars in ./.venv/lib/python3.12/site-packages (from ultralytics) (1.33.1)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in ./.venv/lib/python3.12/site-packages (from ultralytics) (2.0.17)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (4.60.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in ./.venv/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in ./.venv/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests>=2.23.0->ultralytics) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.12/site-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.12/site-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.12/site-packages (from requests>=2.23.0->ultralytics) (2025.8.3)\n",
            "Requirement already satisfied: filelock in ./.venv/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in ./.venv/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (4.15.0)\n",
            "Requirement already satisfied: setuptools in ./.venv/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (80.9.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in ./.venv/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (1.14.0)\n",
            "Requirement already satisfied: networkx in ./.venv/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (3.5)\n",
            "Requirement already satisfied: jinja2 in ./.venv/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in ./.venv/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (2025.9.0)\n",
            "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.12/site-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Requirement already satisfied: opencv-python-headless in ./.venv/lib/python3.12/site-packages (4.12.0.88)\n",
            "Requirement already satisfied: numpy<2.3.0,>=2 in ./.venv/lib/python3.12/site-packages (from opencv-python-headless) (2.2.6)\n"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics\n",
        "!pip install opencv-python-headless"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Dfb5uSEuAYeu"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "model = YOLO(\"yolov9e.pt\") #Load model yolo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V1lDZiwhvIeZ",
        "outputId": "d203d2e1-3661-4008-efa6-ed754802930a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: lap in ./.venv/lib/python3.12/site-packages (0.5.12)\n",
            "Requirement already satisfied: numpy>=1.21.6 in ./.venv/lib/python3.12/site-packages (from lap) (2.2.6)\n"
          ]
        }
      ],
      "source": [
        "!pip install lap"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27YVOsV2vMPP"
      },
      "source": [
        "**Export .csv**\n",
        "\n",
        ".csv: frame, track id, class, confidence, x min, y min, x max, y max (absolute positions)\n",
        "\n",
        ".txt: frame, x_center, y_center, width, height, confidence, track_id (normalized by width and height of frame)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "f9O6bH7UaaII"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from coco_classes import COCO_CLASSES  # Import COCO class names\n",
        "\n",
        "def save_csv(results, csv_file, save_conf=False):\n",
        "    \"\"\"Writes YOLO detection results directly to CSV with a header.\"\"\"\n",
        "\n",
        "    # Ensure directory exists\n",
        "    csv_directory = os.path.dirname(csv_file)\n",
        "    os.makedirs(csv_directory, exist_ok=True)\n",
        "\n",
        "    # Define the CSV header\n",
        "    header = \"frame,id,class,confidence,xmin,ymin,xmax,ymax\\n\"\n",
        "\n",
        "    # Check if the file exists\n",
        "    first_write = not os.path.exists(csv_file)\n",
        "\n",
        "    print(\"Processing detection results frame by frame...\")\n",
        "\n",
        "    with open(csv_file, mode='a') as f:  # Open file in append mode\n",
        "        if first_write:\n",
        "            f.write(header)  # Write header only if file is newly created\n",
        "\n",
        "        for i, result in enumerate(results):  # No `list(results)`, iterate generator directly\n",
        "            is_obb = result.obb is not None   #สร้าง bounding box\n",
        "            boxes = result.obb if is_obb else result.boxes\n",
        "\n",
        "            if len(boxes) == 0:\n",
        "                continue  # Skip frames with no detections\n",
        "\n",
        "            print(f\"Frame {i+1}: {len(boxes)} detections found\")\n",
        "\n",
        "            for d in boxes:\n",
        "                c = int(d.cls.item())\n",
        "                class_name = COCO_CLASSES.get(c, f\"unknown_{c}\")\n",
        "                conf = float(d.conf.item())\n",
        "                id = None if d.id is None else int(d.id.item())\n",
        "\n",
        "                if is_obb:\n",
        "                    x_min, y_min, x_max, y_max = d.xyxy[0].cpu().numpy()\n",
        "                else:\n",
        "                    x_min, y_min, x_max, y_max = d.xyxy[0].cpu().numpy()\n",
        "\n",
        "                # Convert row data to CSV format\n",
        "                row = f\"{i+1},{id},{class_name},{conf if save_conf else ''},{x_min},{y_min},{x_max},{y_max}\\n\"\n",
        "\n",
        "                f.write(row)  # Write data line-by-line to save RAM\n",
        "\n",
        "    print(f\"CSV saved successfully: {csv_file}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Tuh5Vn_glDn"
      },
      "source": [
        "# Asoke intersection\n",
        "For the asoke north videos, we have 3 videos which are TAI_0001, TAI_0002, TAI_0003 (can find in Asoke north video folder)\n",
        "\n",
        "If you have the new .yaml files you need to change it at tracker.\n",
        "\n",
        "**Don't FORGET to change directories of source, project path, csv path !!!**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7WJ46shukhd",
        "outputId": "ea5f3906-6697-47f5-d8fe-b37095ea01ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing detection results frame by frame...\n",
            "\n",
            "video 1/1 (frame 1/35967) /workspaces/kaimook-help/file/asoke/TAI720_01.MOV: 384x640 5 motorcycles, 2181.3ms\n",
            "Frame 1: 5 detections found\n",
            "video 1/1 (frame 2/35967) /workspaces/kaimook-help/file/asoke/TAI720_01.MOV: 384x640 5 motorcycles, 1923.3ms\n",
            "Frame 2: 5 detections found\n",
            "video 1/1 (frame 3/35967) /workspaces/kaimook-help/file/asoke/TAI720_01.MOV: 384x640 5 motorcycles, 1940.8ms\n",
            "Frame 3: 5 detections found\n",
            "video 1/1 (frame 4/35967) /workspaces/kaimook-help/file/asoke/TAI720_01.MOV: 384x640 5 motorcycles, 2000.3ms\n",
            "Frame 4: 5 detections found\n",
            "video 1/1 (frame 5/35967) /workspaces/kaimook-help/file/asoke/TAI720_01.MOV: 384x640 5 motorcycles, 1961.3ms\n",
            "Frame 5: 5 detections found\n",
            "video 1/1 (frame 6/35967) /workspaces/kaimook-help/file/asoke/TAI720_01.MOV: 384x640 5 motorcycles, 1875.7ms\n",
            "Frame 6: 5 detections found\n",
            "video 1/1 (frame 7/35967) /workspaces/kaimook-help/file/asoke/TAI720_01.MOV: 384x640 5 motorcycles, 1912.4ms\n",
            "Frame 7: 5 detections found\n",
            "video 1/1 (frame 8/35967) /workspaces/kaimook-help/file/asoke/TAI720_01.MOV: 384x640 5 motorcycles, 1841.4ms\n",
            "Frame 8: 5 detections found\n",
            "video 1/1 (frame 9/35967) /workspaces/kaimook-help/file/asoke/TAI720_01.MOV: 384x640 5 motorcycles, 1940.1ms\n",
            "Frame 9: 5 detections found\n",
            "video 1/1 (frame 10/35967) /workspaces/kaimook-help/file/asoke/TAI720_01.MOV: 384x640 5 motorcycles, 1899.6ms\n",
            "Frame 10: 5 detections found\n",
            "video 1/1 (frame 11/35967) /workspaces/kaimook-help/file/asoke/TAI720_01.MOV: 384x640 5 motorcycles, 1918.4ms\n",
            "Frame 11: 5 detections found\n",
            "video 1/1 (frame 12/35967) /workspaces/kaimook-help/file/asoke/TAI720_01.MOV: 384x640 5 motorcycles, 2117.7ms\n",
            "Frame 12: 5 detections found\n",
            "video 1/1 (frame 13/35967) /workspaces/kaimook-help/file/asoke/TAI720_01.MOV: 384x640 5 motorcycles, 1937.4ms\n",
            "Frame 13: 5 detections found\n",
            "video 1/1 (frame 14/35967) /workspaces/kaimook-help/file/asoke/TAI720_01.MOV: 384x640 5 motorcycles, 2128.4ms\n",
            "Frame 14: 5 detections found\n",
            "video 1/1 (frame 15/35967) /workspaces/kaimook-help/file/asoke/TAI720_01.MOV: 384x640 5 motorcycles, 1988.3ms\n",
            "Frame 15: 5 detections found\n",
            "video 1/1 (frame 16/35967) /workspaces/kaimook-help/file/asoke/TAI720_01.MOV: 384x640 5 motorcycles, 1957.3ms\n",
            "Frame 16: 5 detections found\n",
            "video 1/1 (frame 17/35967) /workspaces/kaimook-help/file/asoke/TAI720_01.MOV: 384x640 5 motorcycles, 1959.7ms\n",
            "Frame 17: 5 detections found\n",
            "video 1/1 (frame 18/35967) /workspaces/kaimook-help/file/asoke/TAI720_01.MOV: 384x640 5 motorcycles, 1880.6ms\n",
            "Frame 18: 5 detections found\n",
            "video 1/1 (frame 19/35967) /workspaces/kaimook-help/file/asoke/TAI720_01.MOV: 384x640 5 motorcycles, 1889.7ms\n",
            "Frame 19: 5 detections found\n",
            "video 1/1 (frame 20/35967) /workspaces/kaimook-help/file/asoke/TAI720_01.MOV: 384x640 5 motorcycles, 1970.5ms\n",
            "Frame 20: 5 detections found\n",
            "video 1/1 (frame 21/35967) /workspaces/kaimook-help/file/asoke/TAI720_01.MOV: 384x640 5 motorcycles, 1862.2ms\n",
            "Frame 21: 5 detections found\n",
            "video 1/1 (frame 22/35967) /workspaces/kaimook-help/file/asoke/TAI720_01.MOV: 384x640 5 motorcycles, 1871.6ms\n",
            "Frame 22: 5 detections found\n",
            "video 1/1 (frame 23/35967) /workspaces/kaimook-help/file/asoke/TAI720_01.MOV: 384x640 5 motorcycles, 1839.3ms\n",
            "Frame 23: 5 detections found\n",
            "video 1/1 (frame 24/35967) /workspaces/kaimook-help/file/asoke/TAI720_01.MOV: 384x640 5 motorcycles, 1800.3ms\n",
            "Frame 24: 5 detections found\n",
            "video 1/1 (frame 25/35967) /workspaces/kaimook-help/file/asoke/TAI720_01.MOV: 384x640 5 motorcycles, 1808.3ms\n",
            "Frame 25: 5 detections found\n",
            "video 1/1 (frame 26/35967) /workspaces/kaimook-help/file/asoke/TAI720_01.MOV: 384x640 5 motorcycles, 1796.3ms\n",
            "Frame 26: 5 detections found\n",
            "video 1/1 (frame 27/35967) /workspaces/kaimook-help/file/asoke/TAI720_01.MOV: 384x640 5 motorcycles, 1803.2ms\n",
            "Frame 27: 5 detections found\n",
            "video 1/1 (frame 28/35967) /workspaces/kaimook-help/file/asoke/TAI720_01.MOV: 384x640 5 motorcycles, 1769.2ms\n",
            "Frame 28: 5 detections found\n",
            "video 1/1 (frame 29/35967) /workspaces/kaimook-help/file/asoke/TAI720_01.MOV: 384x640 5 motorcycles, 1856.1ms\n",
            "Frame 29: 5 detections found\n",
            "video 1/1 (frame 30/35967) /workspaces/kaimook-help/file/asoke/TAI720_01.MOV: 384x640 5 motorcycles, 1856.5ms\n",
            "Frame 30: 5 detections found\n",
            "video 1/1 (frame 31/35967) /workspaces/kaimook-help/file/asoke/TAI720_01.MOV: 384x640 5 motorcycles, 1970.3ms\n",
            "Frame 31: 5 detections found\n",
            "video 1/1 (frame 32/35967) /workspaces/kaimook-help/file/asoke/TAI720_01.MOV: 384x640 5 motorcycles, 2005.0ms\n",
            "Frame 32: 5 detections found\n",
            "video 1/1 (frame 33/35967) /workspaces/kaimook-help/file/asoke/TAI720_01.MOV: 384x640 5 motorcycles, 1884.8ms\n",
            "Frame 33: 5 detections found\n",
            "video 1/1 (frame 34/35967) /workspaces/kaimook-help/file/asoke/TAI720_01.MOV: 384x640 5 motorcycles, 1872.8ms\n",
            "Frame 34: 5 detections found\n",
            "video 1/1 (frame 35/35967) /workspaces/kaimook-help/file/asoke/TAI720_01.MOV: 384x640 5 motorcycles, 1864.4ms\n",
            "Frame 35: 5 detections found\n",
            "video 1/1 (frame 36/35967) /workspaces/kaimook-help/file/asoke/TAI720_01.MOV: 384x640 4 motorcycles, 1835.7ms\n",
            "Frame 36: 4 detections found\n",
            "video 1/1 (frame 37/35967) /workspaces/kaimook-help/file/asoke/TAI720_01.MOV: 384x640 4 motorcycles, 1902.9ms\n",
            "Frame 37: 4 detections found\n",
            "video 1/1 (frame 38/35967) /workspaces/kaimook-help/file/asoke/TAI720_01.MOV: 384x640 4 motorcycles, 1931.4ms\n",
            "Frame 38: 4 detections found\n",
            "video 1/1 (frame 39/35967) /workspaces/kaimook-help/file/asoke/TAI720_01.MOV: 384x640 4 motorcycles, 1893.4ms\n",
            "Frame 39: 4 detections found\n",
            "video 1/1 (frame 40/35967) /workspaces/kaimook-help/file/asoke/TAI720_01.MOV: 384x640 4 motorcycles, 1840.3ms\n",
            "Frame 40: 4 detections found\n",
            "video 1/1 (frame 41/35967) /workspaces/kaimook-help/file/asoke/TAI720_01.MOV: 384x640 4 motorcycles, 1872.1ms\n",
            "Frame 41: 4 detections found\n",
            "video 1/1 (frame 42/35967) /workspaces/kaimook-help/file/asoke/TAI720_01.MOV: 384x640 4 motorcycles, 1887.2ms\n",
            "Frame 42: 4 detections found\n",
            "video 1/1 (frame 43/35967) /workspaces/kaimook-help/file/asoke/TAI720_01.MOV: 384x640 4 motorcycles, 1865.0ms\n",
            "Frame 43: 4 detections found\n",
            "video 1/1 (frame 44/35967) /workspaces/kaimook-help/file/asoke/TAI720_01.MOV: 384x640 4 motorcycles, 1917.6ms\n",
            "Frame 44: 4 detections found\n",
            "video 1/1 (frame 45/35967) /workspaces/kaimook-help/file/asoke/TAI720_01.MOV: 384x640 4 motorcycles, 1822.3ms\n",
            "Frame 45: 4 detections found\n",
            "video 1/1 (frame 46/35967) /workspaces/kaimook-help/file/asoke/TAI720_01.MOV: 384x640 4 motorcycles, 1863.6ms\n",
            "Frame 46: 4 detections found\n",
            "video 1/1 (frame 47/35967) /workspaces/kaimook-help/file/asoke/TAI720_01.MOV: 384x640 4 motorcycles, 1876.8ms\n",
            "Frame 47: 4 detections found\n",
            "video 1/1 (frame 48/35967) /workspaces/kaimook-help/file/asoke/TAI720_01.MOV: 384x640 4 motorcycles, 1819.7ms\n",
            "Frame 48: 4 detections found\n",
            "video 1/1 (frame 49/35967) /workspaces/kaimook-help/file/asoke/TAI720_01.MOV: 384x640 4 motorcycles, 1817.7ms\n",
            "Frame 49: 4 detections found\n",
            "video 1/1 (frame 50/35967) /workspaces/kaimook-help/file/asoke/TAI720_01.MOV: 384x640 4 motorcycles, 1878.9ms\n",
            "Frame 50: 4 detections found\n",
            "video 1/1 (frame 51/35967) /workspaces/kaimook-help/file/asoke/TAI720_01.MOV: 384x640 4 motorcycles, 1839.3ms\n",
            "Frame 51: 4 detections found\n",
            "video 1/1 (frame 52/35967) /workspaces/kaimook-help/file/asoke/TAI720_01.MOV: 384x640 4 motorcycles, 1857.6ms\n",
            "Frame 52: 4 detections found\n",
            "video 1/1 (frame 53/35967) /workspaces/kaimook-help/file/asoke/TAI720_01.MOV: 384x640 4 motorcycles, 1868.4ms\n",
            "Frame 53: 4 detections found\n",
            "video 1/1 (frame 54/35967) /workspaces/kaimook-help/file/asoke/TAI720_01.MOV: 384x640 4 motorcycles, 1880.6ms\n",
            "Frame 54: 4 detections found\n",
            "video 1/1 (frame 55/35967) /workspaces/kaimook-help/file/asoke/TAI720_01.MOV: 384x640 4 motorcycles, 1842.9ms\n",
            "Frame 55: 4 detections found\n",
            "video 1/1 (frame 56/35967) /workspaces/kaimook-help/file/asoke/TAI720_01.MOV: 384x640 4 motorcycles, 1839.9ms\n",
            "Frame 56: 4 detections found\n",
            "video 1/1 (frame 57/35967) /workspaces/kaimook-help/file/asoke/TAI720_01.MOV: 384x640 4 motorcycles, 1887.8ms\n",
            "Frame 57: 4 detections found\n",
            "video 1/1 (frame 58/35967) /workspaces/kaimook-help/file/asoke/TAI720_01.MOV: 384x640 4 motorcycles, 1880.5ms\n",
            "Frame 58: 4 detections found\n",
            "video 1/1 (frame 59/35967) /workspaces/kaimook-help/file/asoke/TAI720_01.MOV: 384x640 4 motorcycles, 1847.3ms\n",
            "Frame 59: 4 detections found\n",
            "video 1/1 (frame 60/35967) /workspaces/kaimook-help/file/asoke/TAI720_01.MOV: 384x640 4 motorcycles, 1879.4ms\n",
            "Frame 60: 4 detections found\n",
            "video 1/1 (frame 61/35967) /workspaces/kaimook-help/file/asoke/TAI720_01.MOV: 384x640 4 motorcycles, 1899.5ms\n",
            "Frame 61: 4 detections found\n",
            "video 1/1 (frame 62/35967) /workspaces/kaimook-help/file/asoke/TAI720_01.MOV: 384x640 4 motorcycles, 1863.3ms\n",
            "Frame 62: 4 detections found\n",
            "video 1/1 (frame 63/35967) /workspaces/kaimook-help/file/asoke/TAI720_01.MOV: 384x640 4 motorcycles, 1856.7ms\n",
            "Frame 63: 4 detections found\n",
            "video 1/1 (frame 64/35967) /workspaces/kaimook-help/file/asoke/TAI720_01.MOV: 384x640 4 motorcycles, 1881.4ms\n",
            "Frame 64: 4 detections found\n",
            "video 1/1 (frame 65/35967) /workspaces/kaimook-help/file/asoke/TAI720_01.MOV: 384x640 4 motorcycles, 1868.6ms\n",
            "Frame 65: 4 detections found\n",
            "video 1/1 (frame 66/35967) /workspaces/kaimook-help/file/asoke/TAI720_01.MOV: 384x640 4 motorcycles, 1874.5ms\n",
            "Frame 66: 4 detections found\n",
            "video 1/1 (frame 67/35967) /workspaces/kaimook-help/file/asoke/TAI720_01.MOV: 384x640 4 motorcycles, 1860.0ms\n",
            "Frame 67: 4 detections found\n",
            "video 1/1 (frame 68/35967) /workspaces/kaimook-help/file/asoke/TAI720_01.MOV: 384x640 4 motorcycles, 1858.9ms\n",
            "Frame 68: 4 detections found\n",
            "video 1/1 (frame 69/35967) /workspaces/kaimook-help/file/asoke/TAI720_01.MOV: 384x640 4 motorcycles, 1851.6ms\n",
            "Frame 69: 4 detections found\n",
            "video 1/1 (frame 70/35967) /workspaces/kaimook-help/file/asoke/TAI720_01.MOV: 384x640 4 motorcycles, 1852.2ms\n",
            "Frame 70: 4 detections found\n",
            "video 1/1 (frame 71/35967) /workspaces/kaimook-help/file/asoke/TAI720_01.MOV: 384x640 4 motorcycles, 1908.9ms\n",
            "Frame 71: 4 detections found\n",
            "video 1/1 (frame 72/35967) /workspaces/kaimook-help/file/asoke/TAI720_01.MOV: 384x640 4 motorcycles, 1901.2ms\n",
            "Frame 72: 4 detections found\n",
            "video 1/1 (frame 73/35967) /workspaces/kaimook-help/file/asoke/TAI720_01.MOV: 384x640 4 motorcycles, 1941.9ms\n",
            "Frame 73: 4 detections found\n",
            "video 1/1 (frame 74/35967) /workspaces/kaimook-help/file/asoke/TAI720_01.MOV: 384x640 4 motorcycles, 1821.8ms\n",
            "Frame 74: 4 detections found\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m      7\u001b[39m results = model.track(source=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mfile/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/TAI720_01.MOV\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      8\u001b[39m                       tracker=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mfile/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/bytetrack_for_asoke.yml\u001b[39m\u001b[33m\"\u001b[39m, classes = \u001b[32m3\u001b[39m,\n\u001b[32m      9\u001b[39m                       stream=\u001b[38;5;28;01mTrue\u001b[39;00m, save=\u001b[38;5;28;01mTrue\u001b[39;00m, save_txt=\u001b[38;5;28;01mTrue\u001b[39;00m, save_conf=\u001b[38;5;28;01mTrue\u001b[39;00m, conf=\u001b[32m0.1\u001b[39m, iou= \u001b[32m0.45\u001b[39m, line_width = \u001b[32m2\u001b[39m,\n\u001b[32m     10\u001b[39m                       project=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mfile/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/Asoke_north_tracking_v9_bytetrack\u001b[39m\u001b[33m\"\u001b[39m, verbose = \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m#save_csv\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[43msave_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfile/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mpath\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m/TAI720_01.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_conf\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m end_time = time.time()\n\u001b[32m     16\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mProcessing time: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mend_time\u001b[38;5;250m \u001b[39m-\u001b[38;5;250m \u001b[39mstart_time\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m seconds\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 23\u001b[39m, in \u001b[36msave_csv\u001b[39m\u001b[34m(results, csv_file, save_conf)\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m first_write:\n\u001b[32m     21\u001b[39m     f.write(header)  \u001b[38;5;66;03m# Write header only if file is newly created\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# No `list(results)`, iterate generator directly\u001b[39;49;00m\n\u001b[32m     24\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_obb\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43mobb\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m   \u001b[49m\u001b[38;5;66;43;03m#สร้าง bounding box\u001b[39;49;00m\n\u001b[32m     25\u001b[39m \u001b[43m    \u001b[49m\u001b[43mboxes\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43mobb\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mis_obb\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43mboxes\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/kaimook-help/.venv/lib/python3.12/site-packages/torch/utils/_contextlib.py:59\u001b[39m, in \u001b[36m_wrap_generator.<locals>.generator_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     56\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     57\u001b[39m             \u001b[38;5;66;03m# Pass the last request to the generator and get its response\u001b[39;00m\n\u001b[32m     58\u001b[39m             \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m                 response = \u001b[43mgen\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     61\u001b[39m \u001b[38;5;66;03m# We let the exceptions raised above by the generator's `.throw` or\u001b[39;00m\n\u001b[32m     62\u001b[39m \u001b[38;5;66;03m# `.send` methods bubble up to our caller, except for StopIteration\u001b[39;00m\n\u001b[32m     63\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     64\u001b[39m     \u001b[38;5;66;03m# The generator informed us that it is done: take whatever its\u001b[39;00m\n\u001b[32m     65\u001b[39m     \u001b[38;5;66;03m# returned value (if any) was and indicate that we're done too\u001b[39;00m\n\u001b[32m     66\u001b[39m     \u001b[38;5;66;03m# by returning it (see docs for python's return-statement).\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/kaimook-help/.venv/lib/python3.12/site-packages/ultralytics/engine/predictor.py:336\u001b[39m, in \u001b[36mBasePredictor.stream_inference\u001b[39m\u001b[34m(self, source, model, *args, **kwargs)\u001b[39m\n\u001b[32m    334\u001b[39m \u001b[38;5;66;03m# Inference\u001b[39;00m\n\u001b[32m    335\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m profilers[\u001b[32m1\u001b[39m]:\n\u001b[32m--> \u001b[39m\u001b[32m336\u001b[39m     preds = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    337\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.embed:\n\u001b[32m    338\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m [preds] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(preds, torch.Tensor) \u001b[38;5;28;01melse\u001b[39;00m preds  \u001b[38;5;66;03m# yield embedding tensors\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/kaimook-help/.venv/lib/python3.12/site-packages/ultralytics/engine/predictor.py:184\u001b[39m, in \u001b[36mBasePredictor.inference\u001b[39m\u001b[34m(self, im, *args, **kwargs)\u001b[39m\n\u001b[32m    178\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Run inference on a given image using the specified model and arguments.\"\"\"\u001b[39;00m\n\u001b[32m    179\u001b[39m visualize = (\n\u001b[32m    180\u001b[39m     increment_path(\u001b[38;5;28mself\u001b[39m.save_dir / Path(\u001b[38;5;28mself\u001b[39m.batch[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m]).stem, mkdir=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    181\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.visualize \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.source_type.tensor)\n\u001b[32m    182\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    183\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m184\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugment\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43maugment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43membed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/kaimook-help/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/kaimook-help/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/kaimook-help/.venv/lib/python3.12/site-packages/ultralytics/nn/autobackend.py:637\u001b[39m, in \u001b[36mAutoBackend.forward\u001b[39m\u001b[34m(self, im, augment, visualize, embed, **kwargs)\u001b[39m\n\u001b[32m    635\u001b[39m \u001b[38;5;66;03m# PyTorch\u001b[39;00m\n\u001b[32m    636\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.pt \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.nn_module:\n\u001b[32m--> \u001b[39m\u001b[32m637\u001b[39m     y = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugment\u001b[49m\u001b[43m=\u001b[49m\u001b[43maugment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[43m=\u001b[49m\u001b[43membed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    639\u001b[39m \u001b[38;5;66;03m# TorchScript\u001b[39;00m\n\u001b[32m    640\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.jit:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/kaimook-help/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/kaimook-help/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/kaimook-help/.venv/lib/python3.12/site-packages/ultralytics/nn/tasks.py:139\u001b[39m, in \u001b[36mBaseModel.forward\u001b[39m\u001b[34m(self, x, *args, **kwargs)\u001b[39m\n\u001b[32m    137\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):  \u001b[38;5;66;03m# for cases of training and validating while training.\u001b[39;00m\n\u001b[32m    138\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.loss(x, *args, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/kaimook-help/.venv/lib/python3.12/site-packages/ultralytics/nn/tasks.py:157\u001b[39m, in \u001b[36mBaseModel.predict\u001b[39m\u001b[34m(self, x, profile, visualize, augment, embed)\u001b[39m\n\u001b[32m    155\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m augment:\n\u001b[32m    156\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._predict_augment(x)\n\u001b[32m--> \u001b[39m\u001b[32m157\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_predict_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprofile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/kaimook-help/.venv/lib/python3.12/site-packages/ultralytics/nn/tasks.py:180\u001b[39m, in \u001b[36mBaseModel._predict_once\u001b[39m\u001b[34m(self, x, profile, visualize, embed)\u001b[39m\n\u001b[32m    178\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m profile:\n\u001b[32m    179\u001b[39m     \u001b[38;5;28mself\u001b[39m._profile_one_layer(m, x, dt)\n\u001b[32m--> \u001b[39m\u001b[32m180\u001b[39m x = \u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# run\u001b[39;00m\n\u001b[32m    181\u001b[39m y.append(x \u001b[38;5;28;01mif\u001b[39;00m m.i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.save \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# save output\u001b[39;00m\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m visualize:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/kaimook-help/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/kaimook-help/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/kaimook-help/.venv/lib/python3.12/site-packages/ultralytics/nn/modules/block.py:922\u001b[39m, in \u001b[36mRepNCSPELAN4.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    920\u001b[39m y = \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m.cv1(x).chunk(\u001b[32m2\u001b[39m, \u001b[32m1\u001b[39m))\n\u001b[32m    921\u001b[39m y.extend((m(y[-\u001b[32m1\u001b[39m])) \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;28mself\u001b[39m.cv2, \u001b[38;5;28mself\u001b[39m.cv3])\n\u001b[32m--> \u001b[39m\u001b[32m922\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.cv4(\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m)\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "# Asoke nrth with YOLOv9e + Bytetrack and bytetrack_for_asoke.yaml\n",
        "# TAI_01.MOV\n",
        "# Don't FORGET to change directories of source, project path, csv path\n",
        "path = \"asoke\"\n",
        "\n",
        "start_time = time.time()\n",
        "results = model.track(source=f\"asset/{path}/TAI720_01.MOV\",\n",
        "                      tracker=f\"asset/{path}/bytetrack_for_asoke.yml\", classes = 3,\n",
        "                      stream=True, save=True, save_txt=True, save_conf=True, conf=0.1, iou= 0.45, line_width = 2,\n",
        "                      project=f\"asset/{path}/Asoke_north_tracking_v9_bytetrack\", verbose = True)\n",
        "\n",
        "#save_csv\n",
        "save_csv(results, f\"asset/{path}/TAI720_01.csv\", save_conf=True)\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"Processing time: {end_time - start_time} seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "IgosFAko7tnr"
      },
      "outputs": [],
      "source": [
        "#Asoke north with YOLOv9e + Bytetrack and bytetrack_for_asoke.yaml\n",
        "#TAI_02.MOV\n",
        "#Don't FORGET to change directories of source, project path, csv path\n",
        "results = model.track(source=f\"/asset/{path}/TAI720_02.MOV\",\n",
        "                      tracker=f\"/asset/{path}/bytetrack_for_asoke.yaml\", classes = 3,\n",
        "                      stream=True, save=True, save_txt=True, save_conf=True, conf=0.1, iou= 0.45, line_width = 2,\n",
        "                      project=f\"/asset/{path}/Asoke_north_tracking_v9_bytetrack\")\n",
        "\n",
        "# Now results is a list, and we can safely pass it to save_csv\n",
        "save_csv(results, f\"/asset/{path}/TAI720_02.csv\", save_conf=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Vq5UWisB8Hnk",
        "outputId": "1e9a9962-c554-48a0-d640-3ddedfe2e3fb"
      },
      "outputs": [],
      "source": [
        "#Asoke north with YOLOv9e + Bytetrack and bytetrack_for_asoke.yaml\n",
        "#TAI_03.MOV\n",
        "#Don't FORGET to change directories of source, project path, csv path\n",
        "results = model.track(source=f\"/asset/{path}/TAI720_03.MOV\",\n",
        "                      tracker=f\"/asset/{path}/bytetrack_for_asoke.yaml\", classes = 3,\n",
        "                      stream=True, save=True, save_txt=True, save_conf=True, conf=0.1, iou= 0.45, line_width = 2,\n",
        "                      project=f\"/asset/{path}/Asoke_north_tracking_v9_bytetrack\")\n",
        "\n",
        "# Now results is a list, and we can safely pass it to save_csv\n",
        "save_csv(results, \"/content/drive/MyDrive/Asoke_intersection/TAI720_03.csv\", save_conf=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMqitM-pJWIK"
      },
      "source": [
        "# Makkasan\n",
        "For the Makkasan videos, we have 4 videos which are Makkasan_FULL_1, Makkasan_FULL_2, Makkasan_FULL_3, Makkasan_FULL_4 (can find in Makkasan_210325 in Makkasan folder)\n",
        "\n",
        "If you have the new .yaml files you need to change it at tracker.\n",
        "\n",
        "**Don't FORGET to change directories of source, project path, csv path !!!**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZ2QN-Wz4ap_"
      },
      "source": [
        "## For trying/ testing tracking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "collapsed": true,
        "id": "4WW7Z2ASJeac"
      },
      "outputs": [],
      "source": [
        "#Makkasan_trim_20s with YOLOv9e + Bytetrack\n",
        "#Don't FORGET to change directories of source, project path, csv path\n",
        "results = model.track(source=\"/content/drive/MyDrive/code & dataset/Makkasan/Makkasan_trim_20s.mp4\",\n",
        "                      tracker= \"/content/drive/MyDrive/poom/Bytetrack/bytetrack_for_testing_Makkasan_.yaml\", classes = 3,\n",
        "                      stream=True, save=True, save_txt=True, save_conf=True, conf=0.1, iou= 0.45, line_width = 2, imgsz = [1088, 1920], project=\"/content/drive/MyDrive/poom/Makkasan_test_tracking_v9_bytetrack\")\n",
        "\n",
        "# Now results is a list, and we can safely pass it to save_csv\n",
        "save_csv(results, \"/content/drive/MyDrive/Makkasan/Makkasan_test_tracking_v9_bytetrack/CSV/Testing.csv\", save_conf=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xxrsQ0Q3nfT"
      },
      "source": [
        "Example U turn video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "K8ISOlx0uFTy"
      },
      "outputs": [],
      "source": [
        "#Makkasan_ExUturn with YOLOv9e + Bytetrack\n",
        "#Don't FORGET to change directories of source, project path, csv path\n",
        "project_path=\"/content/drive/MyDrive/poom/Makkasan_ExUturn\"\n",
        "\n",
        "results = model.track(source=\"/content/drive/MyDrive/code & dataset/Makkasan/Makkasan_ExUturn.mp4\",\n",
        "                      tracker= \"/content/drive/MyDrive/poom/Bytetrack/ิbytetrackyaml/bytetrack_best.yaml\", classes = 3,\n",
        "                      stream=True, save=True, save_txt=True, save_conf=True, conf=0.05, iou= 0.45, line_width = 2, imgsz = [1088, 1920], project= project_path)\n",
        "\n",
        "save_csv(results, project_path + \"/CSV/ExUturn.csv\", save_conf=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "xXhirUD-YGBA"
      },
      "outputs": [],
      "source": [
        "#Uturn_trim_1car with YOLOv9e + Bytetrack\n",
        "#Don't FORGET to change directories of source, project path, csv path\n",
        "project_path=\"/content/drive/MyDrive/poom/Makkasan_ExUturn\"\n",
        "\n",
        "results = model.track(source=\"/content/drive/MyDrive/code & dataset/Makkasan/Uturn_trim_1car.mp4\",\n",
        "                      tracker= \"/content/drive/MyDrive/poom/Bytetrack/ิbytetrackyaml/bytetrack_best.yaml\", classes = 3,\n",
        "                      stream=True, save=True, save_txt=True, save_conf=True, conf=0.05, iou= 0.45, line_width = 2, imgsz = [1088, 1920], project= project_path)\n",
        "\n",
        "save_csv(results, project_path + \"/CSV/uturn1.csv\", save_conf=True)\n",
        "\n",
        "for r in results:\n",
        "    boxes = r.boxes  # Boxes object for bbox outputs\n",
        "    masks = r.masks  # Masks object for segment masks outputs\n",
        "    probs = r.probs  # Class probabilities for classification outputs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VqUt-AtCczPD"
      },
      "source": [
        "## Tracking whole video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PnntX8CidBIe"
      },
      "outputs": [],
      "source": [
        "#Makkasan_FULL_1 with YOLOv9e + Bytetrack\n",
        "#Don't FORGET to change directories of source, project path, csv path\n",
        "project_path=\"/content/drive/MyDrive/poom/Makkasan_FULL\"\n",
        "\n",
        "results = model.track(source=\"/content/drive/MyDrive/code & dataset/Makkasan/Makkasan_210325/Makkasan_FULL_1.mp4\",\n",
        "                      tracker= \"/content/drive/MyDrive/poom/Bytetrack/ิbytetrackyaml/bytetrack_best.yaml\", classes = 3,\n",
        "                      name = 'Makkasan_FULL_1', stream=True, save=True, save_txt=True, save_conf=True, conf=0.05, iou= 0.45, line_width = 2, imgsz = [1088, 1920], project= project_path)\n",
        "\n",
        "save_csv(results, \"/content/drive/MyDrive/poom/Makkasan_FULL/CSV/Makkasan_Full_1.csv\", save_conf=True)\n",
        "\n",
        "for r in results:\n",
        "    boxes = r.boxes  # Boxes object for bbox outputs\n",
        "    masks = r.masks  # Masks object for segment masks outputs\n",
        "    probs = r.probs  # Class probabilities for classification outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s7ywkBdhKKCs"
      },
      "outputs": [],
      "source": [
        "#Makkasan_FULL_2 with YOLOv9e + Bytetrack\n",
        "#Don't FORGET to change directories of source, project path, csv path\n",
        "project_path=\"/content/drive/MyDrive/poom/Makkasan_FULL\"\n",
        "\n",
        "results_2 = model.track(source=\"/content/drive/MyDrive/code & dataset/Makkasan/Makkasan_210325/Makkasan_FULL_2.mp4\",\n",
        "                      tracker= \"/content/drive/MyDrive/poom/Bytetrack/ิbytetrackyaml/bytetrack_best.yaml\", classes = 3,\n",
        "                      name = 'Makkasan_FULL_2',stream=True, save=True, save_txt=True, save_conf=True, conf=0.05, iou= 0.45, line_width = 2, imgsz = [1088, 1920], project= project_path)\n",
        "\n",
        "save_csv(results_2, \"/content/drive/MyDrive/poom/Makkasan_FULL/CSV/Makkasan_Full_2.csv\", save_conf=True)\n",
        "\n",
        "for r in results_2:\n",
        "    boxes = r.boxes  # Boxes object for bbox outputs\n",
        "    masks = r.masks  # Masks object for segment masks outputs\n",
        "    probs = r.probs  # Class probabilities for classification outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XPpOQ2qwwWQ9"
      },
      "outputs": [],
      "source": [
        "#Makkasan_FULL_3 with YOLOv9e + Bytetrack\n",
        "#Don't FORGET to change directories of source, project path, csv path\n",
        "project_path=\"/content/drive/MyDrive/poom/Makkasan_FULL\"\n",
        "\n",
        "results_3 = model.track(source=\"/content/drive/MyDrive/code & dataset/Makkasan/Makkasan_210325/Makkasan_FULL_3.mp4\",\n",
        "                      tracker= \"/content/drive/MyDrive/poom/Bytetrack/ิbytetrackyaml/bytetrack_best.yaml\", classes = 3,\n",
        "                      name = 'Makkasan_FULL_3',stream=True, save=True, save_txt=True, save_conf=True, conf=0.05, iou= 0.45, line_width = 2, imgsz = [1088, 1920], project= project_path)\n",
        "\n",
        "save_csv(results_3, \"/content/drive/MyDrive/poom/Makkasan_FULL/CSV/Makkasan_Full_3.csv\", save_conf=True)\n",
        "\n",
        "for r in results_3:\n",
        "    boxes = r.boxes  # Boxes object for bbox outputs\n",
        "    masks = r.masks  # Masks object for segment masks outputs\n",
        "    probs = r.probs  # Class probabilities for classification outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vdsu2HDEwXI2"
      },
      "outputs": [],
      "source": [
        "#Makkasan_FULL_4 with YOLOv9e + Bytetrack\n",
        "#Don't FORGET to change directories of source, project path, csv path\n",
        "project_path=\"/content/drive/MyDrive/poom/Makkasan_FULL\"\n",
        "\n",
        "results_4 = model.track(source=\"/content/drive/MyDrive/code & dataset/Makkasan/Makkasan_210325/Makkasan_FULL_4.mp4\",\n",
        "                      tracker= \"/content/drive/MyDrive/poom/Bytetrack/ิbytetrackyaml/bytetrack_best.yaml\", classes = 3,\n",
        "                      name = 'Makkasan_FULL_4',stream=True, save=True, save_txt=True, save_conf=True, conf=0.05, iou= 0.45, line_width = 2, imgsz = [1088, 1920], project= project_path)\n",
        "\n",
        "save_csv(results_4, \"/content/drive/MyDrive/poom/Makkasan_FULL/CSV/Makkasan_Full_4.csv\", save_conf=True)\n",
        "\n",
        "for r in results_4:\n",
        "    boxes = r.boxes  # Boxes object for bbox outputs\n",
        "    masks = r.masks  # Masks object for segment masks outputs\n",
        "    probs = r.probs  # Class probabilities for classification outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ebs27kToXxQ"
      },
      "source": [
        "## For 3 video clip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "OXNli71xoXgG",
        "outputId": "b0fe5a49-96e3-4dce-8939-3cb5a55610e4"
      },
      "outputs": [],
      "source": [
        "project_path=\"/content/drive/MyDrive/poom/For_3min\"\n",
        "results = model.track(source=\"/content/drive/MyDrive/poom/Interested vdo/Full1_250.mp4\",\n",
        "                      tracker= \"/content/drive/MyDrive/poom/Bytetrack/ิbytetrackyaml/bytetrack_best.yaml\", classes = 3,\n",
        "                      save=True, save_txt=True, save_conf=True, conf=0.05, iou= 0.45, line_width = 2, imgsz = [1088, 1920], project= project_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "BFkN6KAMqnBk",
        "outputId": "6f47955f-2f43-4666-abac-68d75fa2d556"
      },
      "outputs": [],
      "source": [
        "project_path=\"/content/drive/MyDrive/poom/For_3min\"\n",
        "results = model.track(source=\"/content/drive/MyDrive/poom/Interested vdo/Full3_557.mp4\",\n",
        "                      tracker= \"/content/drive/MyDrive/poom/Bytetrack/ิbytetrackyaml/bytetrack_best.yaml\", classes = 3,\n",
        "                      save=True, save_txt=True, save_conf=True, conf=0.05, iou= 0.45, line_width = 2, imgsz = [1088, 1920], project= project_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HjSYut8ltexq"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_1OXMS9tfCf",
        "outputId": "c13a1bff-2e41-4658-e361-85a703aeef1d"
      },
      "outputs": [],
      "source": [
        "project_path=\"/content/drive/MyDrive/poom/For_3min\"\n",
        "results = model.track(source=\"/content/drive/MyDrive/poom/Interested vdo/Full1_1136.mp4\",\n",
        "                      tracker= \"/content/drive/MyDrive/poom/Bytetrack/ิbytetrackyaml/bytetrack_best.yaml\", classes = 3,\n",
        "                      save=True, save_txt=True, save_conf=True, conf=0.05, iou= 0.45, line_width = 2, imgsz = [1088, 1920], project= project_path)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "9ebs27kToXxQ"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
